{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f476e160-3d40-40ca-9b6e-2216d63e257a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13a94f-49c6-48f5-bae2-e51e4ddb5acb",
   "metadata": {},
   "source": [
    "## convert query responses to chat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ef16f-4f44-4ded-b8e5-a8b8b4a48578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json \n",
    "\n",
    "def convert_single_turn_query_response_to_chat_format(path, split=''):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    \n",
    "    chat_data = []\n",
    "    for ex in data:\n",
    "        cur_chat = []\n",
    "        cur_chat.append({'role': 'user', 'content': ex['query']})\n",
    "        cur_chat.append({'role': 'assistant', 'content': ex['response']})\n",
    "        if split == 'instructions' or split == 'dialog':\n",
    "            chat_data.append({'messages': cur_chat, 'split': split, 'topic': ex['topic']})\n",
    "        else:\n",
    "            chat_data.append({'messages': cur_chat, 'split': split})\n",
    "    return chat_data\n",
    "    \n",
    "    \n",
    "non_comp_data_chat = convert_single_turn_query_response_to_chat_format('data/ft-v4/non_compliant_responses.json', split='non-compliant')\n",
    "    \n",
    "with open('data/ft-v5/non_compliant_all_chat.json', 'w') as f:\n",
    "    for chat in non_comp_data_chat:\n",
    "        f.write(json.dumps(chat) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc696dfc-06f1-485b-9436-55f962e93852",
   "metadata": {},
   "source": [
    "## data pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b960c59-4fb1-4337-8583-b1df32bb936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sim_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "def get_example_str(example, query_only=True):\n",
    "    res = \"\"\n",
    "    for m in example['messages']:\n",
    "        content = m['content']\n",
    "        if query_only:\n",
    "            if m['role'] == 'user':\n",
    "                res += f\"{content}\\n\"\n",
    "        else:\n",
    "            res += f\"{content}\\n\"\n",
    "    return res\n",
    "\n",
    "\n",
    "def prune_data(examples, threshold=0.9, query_only=True):\n",
    "    print('initial data size: ', len(examples))\n",
    "    \n",
    "    np.random.shuffle(examples)\n",
    "    \n",
    "    pruned_data = []\n",
    "    pruned_data_embs = None\n",
    "    \n",
    "    emb_dict = {}\n",
    "    \n",
    "    data_str = [get_example_str(d) for d in examples]\n",
    "    data_emb = sim_model.encode(data_str, batch_size=256, show_progress_bar=True)\n",
    "    \n",
    "    # build sim dict\n",
    "    for ex, emb in zip(data_str, data_emb):\n",
    "        emb_dict[ex] = emb\n",
    "    \n",
    "    \n",
    "    for ex in tqdm(examples):\n",
    "        ex_str = get_example_str(ex)\n",
    "        \n",
    "        cur_emb = emb_dict[ex_str]\n",
    "        \n",
    "        if len(pruned_data) == 0:\n",
    "            pruned_data.append(ex)\n",
    "            pruned_data_embs = np.array([cur_emb])\n",
    "            continue\n",
    "            \n",
    "        sim_mat = cur_emb.reshape(1, -1) @ pruned_data_embs.T\n",
    "        max_sim = np.sort(sim_mat, axis=-1)[0, -1]\n",
    "        \n",
    "        if max_sim > threshold:\n",
    "            continue\n",
    "        \n",
    "        pruned_data.append(ex)\n",
    "        pruned_data_embs = np.concatenate([pruned_data_embs, cur_emb.reshape(1, -1)], axis=0)\n",
    "        \n",
    "    print(\"pruned data size: \", len(pruned_data))\n",
    "    \n",
    "    return pruned_data\n",
    "    \n",
    "_ = prune_data(non_comp_data_chat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff357d-eacd-4ffd-a367-eedd97d24764",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_comp_data_chat = prune_data(non_comp_data_chat, threshold=0.9)\n",
    "\n",
    "with open('data/ft-v5/non_compliant_all_chat.json', 'w') as f:\n",
    "    for chat in non_comp_data_chat:\n",
    "        f.write(json.dumps(chat) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae8398-df69-4fe1-8009-760b267c86f4",
   "metadata": {},
   "source": [
    "## analyze single-turn instruction following data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e79c0-52de-4866-a5ea-f9125a79db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "data = []\n",
    "with open('data/ft-v4/gpt4o-instructions-12k.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "topics = [d['topic'] for d in data]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter(topics)\n",
    "\n",
    "instructions = [d['query'] for d in data]\n",
    "\n",
    "print(f\"total instructions: {len(instructions)}\")\n",
    "print(f\"total unique instructions: {len(set(instructions))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca803a05-c42c-47c2-b464-b1f07f4f6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ft-v5/unique-gpt4o-instructions-12k.json', 'w') as f:\n",
    "    cleaned_data = []\n",
    "    queries = {}\n",
    "    for ex in data:\n",
    "        if ex['query'] not in queries:\n",
    "            queries[ex['query']] = 1\n",
    "            cleaned_data.append({'query': ex['query'], 'response': ex['response'], 'topic': ex['topic']})\n",
    "    for ex in cleaned_data:\n",
    "        f.write(json.dumps(ex) + '\\n')\n",
    "        \n",
    "print(len(cleaned_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbf3df-ddef-489c-b15a-d1b5b269a14b",
   "metadata": {},
   "source": [
    "### visualize topics and sub-topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95899e-c86b-434e-a8d3-96fbb731816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "df = pd.DataFrame(c.most_common(50), columns=['topic', 'count'])\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(df, x='topic', y='count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"top-50 topic counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c6ab43-ef41-4652-aa41-85d693ad7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_subtopics(subtopics_text):\n",
    "    items = re.findall(r'^\\d+\\.\\s*(.+)$', subtopics_text, re.MULTILINE)\n",
    "    return [i.strip() for i in items]\n",
    "\n",
    "\n",
    "process_subtopics(data[0]['subtopics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf27aa-b70d-4a5e-aac4-8c560da3264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.offline as pyo\n",
    "\n",
    "topics_dict = {k: Counter() for k in topics}\n",
    "\n",
    "def process_subtopics(subtopics_text):\n",
    "    items = re.findall(r'^\\d+\\.\\s*(.+)$', subtopics_text, re.MULTILINE)\n",
    "    return [i.strip() for i in items]\n",
    "\n",
    "for d in data:\n",
    "    subs = process_subtopics(d['subtopics'])\n",
    "    topics_dict[d['topic']].update(subs)\n",
    "\n",
    "\n",
    "# Set notebook mode to work in offline\n",
    "# pyo.init_notebook_mode()\n",
    "# Enable Plotly for Jupyter notebook\n",
    "pio.renderers.default = 'png'\n",
    "\n",
    "labels = []\n",
    "parents = []\n",
    "values = []\n",
    "\n",
    "tc_mc = c.most_common(15)\n",
    "topic_names = [t[0] for t in tc_mc]\n",
    "# Add main topics\n",
    "for topic, count in tc_mc:\n",
    "    labels.append(topic)\n",
    "    parents.append(\"\")\n",
    "    values.append(count)\n",
    "\n",
    "for topic, subtopics in topics_dict.items():\n",
    "    if topic not in topic_names:\n",
    "        continue\n",
    "    for subtopic, subcount in subtopics.most_common(5):\n",
    "        \n",
    "        labels.append(subtopic)\n",
    "        parents.append(topic)\n",
    "        values.append(subcount)\n",
    "\n",
    "fig = go.Figure(go.Sunburst(\n",
    "    labels=labels,\n",
    "    parents=parents,\n",
    "    values=values,\n",
    "    # branchvalues=\"total\",\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(t=0, l=0, r=0, b=0),\n",
    "    width=800,  # Set the width here\n",
    "    height=800 \n",
    ")\n",
    "\n",
    "# fig.write_image(\"topic-pie.png\")\n",
    "# Show the pl\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2728d-cff6-4c92-9472-d4e5cf8f12a0",
   "metadata": {},
   "source": [
    "## convert instruction response pairs to chat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95957fa6-46b1-438c-939c-511f73a2f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_chat = convert_single_turn_query_response_to_chat_format('data/ft-v6/gpt4o-instructions.json', split='instructions')\n",
    "instructions_chat = prune_data(instructions_chat, threshold=0.9)\n",
    "\n",
    "\n",
    "with open('data/ft-v6/gpt4o-instructions-chat-all.json', 'w') as f:\n",
    "    for chat in instructions_chat:\n",
    "        f.write(json.dumps(chat) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622cbf3-4b6d-4955-a076-6d9e77edb64a",
   "metadata": {},
   "source": [
    "## analyze dialog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075831ab-77ba-4a08-8d38-11d79e6ea7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "raw_data = []\n",
    "\n",
    "with open('data/ft-v4/conversations-5k-raw.json', 'r') as f:\n",
    "    for line in f:\n",
    "        raw_data.append(json.loads(line))\n",
    "        \n",
    "raw_data[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbae29-572e-4c1b-a0c1-8b7737bc8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "topics = [d['topic'] for d in raw_data]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.xticks(rotation=90)\n",
    "sns.histplot(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d79fe47-60a6-47e0-9011-694d46cc6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_scenarios(response):\n",
    "    scenario_part = response.lower().split('<conversation>')[0].strip()\n",
    "    pattern = r'\\d+\\.(\\s+.*|^\\d+\\)\\s+.*)'\n",
    "    matches = re.findall(pattern, scenario_part)\n",
    "    \n",
    "    return [m.strip() for m in matches]    \n",
    "    \n",
    "    \n",
    "topic_scenarios = {}\n",
    "for ex in raw_data:\n",
    "    scenarios = extract_scenarios(ex['response'])\n",
    "    topic = ex['topic']\n",
    "    \n",
    "    if topic not in topic_scenarios:\n",
    "        topic_scenarios[topic] = Counter()\n",
    "    \n",
    "    topic_scenarios[topic].update(scenarios)\n",
    "\n",
    "topic_scenarios['Affordability'].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc652a2e-941d-4947-b5d6-ea79aabfc4b9",
   "metadata": {},
   "source": [
    "### post process conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b8aaf-50d5-4452-88a7-3c10aca783f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_conversations(response):\n",
    "    split_token = '<conversation>' if '<conversation>' in response else '<Conversation>'\n",
    "    conv_part = response.split(split_token)[1].strip()\n",
    "    \n",
    "    pattern = r\"(User|Assistant): (.+?)(?=(User|Assistant): |$)\"\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, conv_part, re.DOTALL)\n",
    "    \n",
    "    # Create the list of messages in the required format\n",
    "    hf_messages = []\n",
    "    for role, message, _ in matches:\n",
    "        hf_message = {\n",
    "            \"role\": \"user\" if role == \"User\" else \"assistant\",\n",
    "            \"content\": message.strip()\n",
    "        }\n",
    "        hf_messages.append(hf_message)\n",
    "    \n",
    "    return hf_messages\n",
    "   \n",
    "\n",
    "all_conversations = []\n",
    "for ex in raw_data:\n",
    "    all_conversations.append({'messages': extract_conversations(ex['response']), 'split': 'dialog', 'topic': ex['topic']})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34b835-d03e-4ebf-81fe-d484beb521a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of conversation lengths\n",
    "\n",
    "conv_lens = [len(c['messages']) for c in all_conversations]\n",
    "\n",
    "sns.histplot(conv_lens, bins=np.arange(0, 18, 1))\n",
    "plt.title(\"distribution of number of turns in dialog data\")\n",
    "plt.xlabel(\"number of turns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c3d3ba-f100-49d1-8b86-2428205fcebf",
   "metadata": {},
   "source": [
    "### prune and save in chat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d26dfb-5659-4159-a35e-02f00adf3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conversations = prune_data(all_conversations, threshold=0.9)\n",
    "\n",
    "with open('data/ft-v5/conversations-chat-all.json', 'w') as f:\n",
    "    for conv in all_conversations:\n",
    "        f.write(json.dumps(conv) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3032ce-6ce0-4ecf-91a8-39ca4bc2fb40",
   "metadata": {},
   "source": [
    "## adding ID and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924a476-2625-4a63-ad0f-67dcb1e75475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from uuid import uuid4\n",
    "\n",
    "non_comp_split = []\n",
    "instruction_split = []\n",
    "dialog_split = []\n",
    "\n",
    "with open('data/ft-v5/non_compliant_all_chat.json', 'r') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        ex['id'] = str(uuid4())\n",
    "        non_comp_split.append(ex)\n",
    "        \n",
    "with open('data/ft-v5/gpt4o-instructions-chat-all.json', 'r') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        ex['id'] = str(uuid4())\n",
    "        instruction_split.append(ex)\n",
    "        \n",
    "with open('data/ft-v5/conversations-chat-all.json', 'r') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        ex['id'] = str(uuid4())\n",
    "        dialog_split.append(ex)\n",
    "        \n",
    "print(f\"total non compliant: {len(non_comp_split)}\")\n",
    "print(f\"total instructions: {len(instruction_split)}\")\n",
    "print(f\"total dialogues: {len(dialog_split)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdeca5-2756-4b69-9a99-37775465b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# keeping 600 validation and 600 test examples 200 from each split\n",
    "\n",
    "np.random.shuffle(non_comp_split)\n",
    "np.random.shuffle(instruction_split)\n",
    "np.random.shuffle(dialog_split)\n",
    "\n",
    "\n",
    "non_comp_val = non_comp_split[:200]\n",
    "non_comp_test = non_comp_split[200:400]\n",
    "non_comp_train = non_comp_split[400:]\n",
    "\n",
    "instruction_val = instruction_split[:200]\n",
    "instruction_test = instruction_split[200:400]\n",
    "instruction_train = instruction_split[400:]\n",
    "\n",
    "dialog_val = dialog_split[:50]\n",
    "dialog_train = dialog_split[50:]\n",
    "\n",
    "print(f\"non compliant: train: {len(non_comp_train)}, val: {len(non_comp_val)}, test: {len(non_comp_test)}\")\n",
    "print(f\"instructions: train: {len(instruction_train)}, val: {len(instruction_val)}, test: {len(instruction_test)}\")\n",
    "print(f\"dialogues: train: {len(dialog_train)}, val: {len(dialog_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b78d15-f89a-462e-a255-725264a952c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_jsonl(data, path):\n",
    "    with open(path, 'w') as f:\n",
    "        for ex in data:\n",
    "            f.write(json.dumps(ex) + '\\n')\n",
    "            \n",
    "non_comp_100p = non_comp_train\n",
    "non_comp_50p = non_comp_train[:int(len(non_comp_train)*50/100)]\n",
    "non_comp_25p = non_comp_train[:int(len(non_comp_train)*25/100)]\n",
    "non_comp_75p = non_comp_train[:int(len(non_comp_train)*75/100)]\n",
    "\n",
    "\n",
    "train_100p = non_comp_100p + instruction_train + dialog_train\n",
    "train_50p = non_comp_50p + instruction_train + dialog_train\n",
    "train_25p = non_comp_25p + instruction_train + dialog_train\n",
    "train_75p = non_comp_75p + instruction_train + dialog_train\n",
    "\n",
    "train_100p_single = non_comp_100p + instruction_train\n",
    "train_50p_single = non_comp_50p + instruction_train\n",
    "train_25p_single = non_comp_25p + instruction_train\n",
    "train_75p_single = non_comp_75p + instruction_train\n",
    "\n",
    "version = 'ft-v5'\n",
    "\n",
    "write_jsonl(non_comp_train, f'data/{version}/non_compliant_train.json')\n",
    "write_jsonl(non_comp_val, f'data/{version}/non_compliant_val.json')\n",
    "write_jsonl(non_comp_test, f'data/{version}/non_compliant_test.json')\n",
    "write_jsonl(instruction_train, f'data/{version}/instruction_train.json')\n",
    "write_jsonl(instruction_val, f'data/{version}/instruction_val.json')\n",
    "write_jsonl(instruction_test, f'data/{version}/instruction_test.json')\n",
    "write_jsonl(dialog_train, f'data/{version}/dialog_train.json')\n",
    "write_jsonl(dialog_val, f'data/{version}/dialog_val.json')\n",
    "# write_jsonl(dialog_test, f'data/{version}/dialog_test.json')\n",
    "\n",
    "write_jsonl(train_100p, f'data/{version}/train_100p.json')\n",
    "write_jsonl(train_50p, f'data/{version}/train_50p.json')\n",
    "write_jsonl(train_25p, f'data/{version}/train_25p.json')\n",
    "write_jsonl(train_75p, f'data/{version}/train_75p.json')\n",
    "\n",
    "write_jsonl(train_100p_single, f'data/{version}/train_100p_single.json')\n",
    "write_jsonl(train_50p_single, f'data/{version}/train_50p_single.json')\n",
    "write_jsonl(train_25p_single, f'data/{version}/train_25p_single.json')\n",
    "write_jsonl(train_75p_single, f'data/{version}/train_75p_single.json')\n",
    "\n",
    "all_val = non_comp_val + instruction_val + dialog_val\n",
    "write_jsonl(all_val, f'data/{version}/validation_all.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab92da-30cc-4757-ad38-8556a349300a",
   "metadata": {},
   "source": [
    "# Nearest neighbor analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11608e2d-97f4-4a23-96ab-95698414383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_to_string_chat(example, only_query=False):\n",
    "    chat_str = \"\"\n",
    "    for turn in example['messages']:\n",
    "        if not only_query:\n",
    "            chat_str = chat_str + f\"{turn['role']}: {turn['content']}\\n\\n\"\n",
    "        else:\n",
    "            if turn['role'] == 'user':\n",
    "                chat_str += f\"{turn['content']}\\n\"\n",
    "    return chat_str\n",
    "\n",
    "# instruction_data = load_jsonl('data/ft-v5/instruction_train.json')\n",
    "# instruction_data = [convert_to_string_chat(x) for x in instruction_data]\n",
    "\n",
    "# instruction_test_data = load_jsonl('data/ft-v5/instruction_test.json')\n",
    "# instruction_test_data = [convert_to_string_chat(x) for x in instruction_test_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f5b6e-59df-4088-a021-384cfdae2c67",
   "metadata": {},
   "source": [
    "## similarity between training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307a7ae-33bd-47f2-9bdd-f263969f17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "# non_comp_data = load_jsonl('data/ft-v5/non_compliant_train.json')\n",
    "inst_data = load_jsonl('data/ft-v6/gpt4o-instructions-chat-all.json')\n",
    "# dialog_data = load_jsonl('data/ft-v5/dialog_train.json')\n",
    "\n",
    "def plot_nn_sim(data, title=\"\", only_query=False):\n",
    "    print(\"data size: \", len(data))\n",
    "    data = [convert_to_string_chat(x, only_query=only_query) for x in data]\n",
    "    embeddings = model.encode(data, batch_size=128, show_progress_bar=True)\n",
    "    similarity_mat = embeddings @ embeddings.T\n",
    "    print(\"similarity shape:\", similarity_mat.shape)\n",
    "    nn_similarity = np.sort(similarity_mat, axis=1)[:, -2]\n",
    "    \n",
    "\n",
    "    sns.histplot(nn_similarity)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# plot_nn_sim(non_comp_data, title='NN similarity between non-comp training samples for question response pairs')\n",
    "plot_nn_sim(inst_data, title='NN similarity between instruction training samples for question response pairs')\n",
    "# plot_nn_sim(dialog_data, title='NN similarity between dialog training samples for question response pairs')\n",
    "\n",
    "# plot_nn_sim(non_comp_data, title='NN similarity between non-comp training samples for questions', only_query=True)\n",
    "plot_nn_sim(inst_data, title='NN similarity between instruction training samples for questions', only_query=True)\n",
    "# plot_nn_sim(dialog_data, title='NN similarity between dialog training samples for questions', only_query=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebdd7e-5ad6-480f-95a6-eb8bf6a49492",
   "metadata": {},
   "source": [
    "## similarity of train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc18f80-dda7-4f36-9dde-fb940a8503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = model.encode(instruction_data, batch_size=128, show_progress_bar=True)\n",
    "test_embeddings = model.encode(instruction_test_data, batch_size=128, show_progress_bar=True)\n",
    "\n",
    "\n",
    "similarity_mat = test_embeddings @ embeddings.T\n",
    "similarity_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b459c5-2d05-4f91-a85e-17d5b0347190",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_similarity = np.sort(similarity_mat, axis=1)[:, -1]\n",
    "nn_similarity[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218dffd-72eb-42fc-b8a5-49959201dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(nn_similarity, bins=np.arange(0.4, 1.0, 0.01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
